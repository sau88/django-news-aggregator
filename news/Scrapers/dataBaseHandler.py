import requests
from lxml import etree
from lxml import html

from datetime import datetime
from .dateTime_logic import Get_DateTime
from bs4 import BeautifulSoup


class django_db_Handler:
    """ 
    This class handels saving of scrapped data into designated table.
    ...

    Methods
    -------
    __init__()
        Holds some constants values

    Save_to_db()
        Saves all data in requested db table
    request_soup()
        Scrape data using BeautifulSoup lib
    request_xml()
        scrape data using lxml lib
    
    """
    def __init__(self, table_name, Datetime_format, website_name, webIcon ):
        
        """
        Attributes
    ----------
    table_name : django model class name
        database table name as defined in model.py
    Datetime_format : str
        Datetime format string for python string ---> datetime object conversion e.g : April 2 2020 10:45 am IST, '%B %d %Y %I:%M %p %Z'
    website_name : str
        Name of website without https header and sub-domain e.g hindustantimes
    webIcon : str
        url link of website favicon or icon.
    
        Return
        ------
        None

        """
        self.table_name = table_name
        self.Datetime_format = Datetime_format
        self.website_name = website_name
        self.webIcon = webIcon
        
        return None
        #self.table_name = table_name
        
    def Save_to_db(self, news_title, page_link, img_src, Datetime ):
        
        """ saves all scraped data into db table.

        Parameters
        ----------
        news_title : str
            post title
        page_link : str
            url string of page
        img_src : str
            image source link
        Datetime : str
            post datetime string e.g April 2 2020 23:45:11 IST
        
        Return value
        ------------
        None

        """
        self.news_title = news_title
        self.page_link = page_link
        self.img_src = img_src
        self.Datetime = Datetime
       

        news_headline = self.table_name()
        
        news_headline.title = news_title
        news_headline.url = page_link
        news_headline.website_name = self.website_name
        news_headline.websiteIcon = self.webIcon
        # If news post datetime not found , in case of live news, 
        if len(Datetime) == 0:
            now = datetime.now()
            news_headline.timeStamp = now.strftime('%Y-%m-%d %H:%M:%S')
        else:
            # convert news posting datetime string into common datetime object
            obj = Get_DateTime()
            datetime_object = obj.String_to_datetime( Datetime, self.Datetime_format )
            news_headline.timeStamp = str(datetime_object)
        # If image is not availabe (some new webs shows only live news schedule of whole day)
        if len(img_src) == 0:
            news_headline.image = "Image Not Availabe"
        else:
            news_headline.image = img_src
        
        news_headline.save()
        return None

class request_Handler:
    """ 
    This class handels web scraping requests generated by scrapers .
    ...

    Methods
    -------
    __init__()
        Holds url

    request_soup()
        Scrape data using BeautifulSoup lib
    request_xml()
        scrape data using lxml lib
    dataCleaner()
        data cleaning 
    
    """

    def __init__(self):
        """ 
        Do nothing

        Parameters
        ----------
        None
        
        Return value
        ------------
        None
        
        """
        
        return None

    def request_xml(self,url):

        """ This method uses python lxml lib which supports 
            xpath search and it is relatively faster.

            Parameters
            ----------
            url : str
                url of website
            
            Return value
            ------------
            lxml.tree object

            Exception
            ------
            requests.exceptions.ConnectTimeout
                If timeout occurs then just pass to avoid program locked-down (default = 5 seconds) 
        """

        self.url = url
        try:
            page = requests.get( url, timeout=5.0)
        except requests.exceptions.ConnectTimeout as timeout:
            return False
        Tree = html.fromstring(page.content)
        return Tree


    def request_soup(self, url):
        """ This method uses python's native BeautifulSoup lib.

            Parameters
            ----------
            url : str
                url of website
            
            Return value
            ------------
            BeautifulSoup object

            Exception
            ------
            requests.exceptions.ConnectTimeout
                If timeout occurs then just pass to avoid program locked-down (default = 5 seconds) 
        """
        self.url = url

        try:
            session = requests.Session()
            session.headers = {"User-Agent": "Googlebot-News"}
            page = session.get( url, verify=False, timeout=5.0)
            
        except requests.exceptions.ConnectTimeout as timeout:
            return False
        soup = BeautifulSoup(page.content, "html.parser")
        return soup


    def dataCleaner(self,List):
        
        """ Extract and clean text string from list. 
        
            Parameters
            ----------
            url : List/array
                List of strings
            
            Return value
            ------------
            st : text string 
        """
        self.List = List

        st = ""
        for x in List:
            st += x
        return st.strip()

